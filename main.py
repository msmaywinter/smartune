import base64
<<<<<<< HEAD
import signal
from datetime import datetime
import json
import os
os.environ["DISABLE_VERSION_CHECK"] = "1"
=======
from datetime import datetime
import json
import os
>>>>>>> origin/main
import shutil
import webbrowser
import eel
import glob
import pandas as pd
import asyncio
from pathlib import Path
import openpyxl
<<<<<<< HEAD
import sys
import threading
=======
>>>>>>> origin/main

from excel_processor import process_excel_file
from model_registry import is_valid_model_name, is_duplicate_model_name, save_model_metadata as save_fn
from openai_generator import generate_by_topics, load_model_metadata as load_model_metadata_fn, finalize_generation
from generation_planner import update_generation_choice as update_generation_choice_fn
from data_editor import load_generated_data as load_generated_data_fn
from state_manager import cleanup_all, load_temp_metadata
<<<<<<< HEAD
from email_manager import register_email, notify_all
from Train import startTrain, question, setTestModel, exportModel
from dotenv import load_dotenv

load_dotenv()

if sys.stdout:
    sys.stdout.reconfigure(encoding='utf-8')

eel.init('web')

=======

eel.init('web')
>>>>>>> origin/main
# ===== ×—×©×™×¤×ª ×¤×•× ×§×¦×™×•×ª ×œ-Eel =====

@eel.expose
def handle_file_upload(filename):
    input_path = os.path.join("uploads", filename)
    result = process_excel_file(input_path)
    if os.path.exists(input_path):
        os.remove(input_path)

    return result

@eel.expose
def save_file_to_server(base64data, filename):
    path = f'uploads/{filename}'
    with open(path, 'wb') as f:
        f.write(base64.b64decode(base64data))

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def delete_model_folder(slug):
    model_path = os.path.join("models", slug)
    if os.path.exists(model_path) and os.path.isdir(model_path):
        shutil.rmtree(model_path)
        print(f"× ××—×§×” ×ª×™×§×™×™×ª ×”××•×“×œ: {slug}")
        return {"success": True}
    return {"success": False, "error": "×ª×™×§×™×™×” ×œ× × ××¦××”"}

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def validate_model_name(name):
    if not is_valid_model_name(name):
        return {"success": False, "error": "×©× ×”××•×“×œ ×™×›×•×œ ×œ×”×›×™×œ ×¨×§ ××•×ª×™×•×ª ×‘×× ×’×œ×™×ª, ××¡×¤×¨×™×, ×¨×•×•×—×™×, ××§×£ ×•×§×• ×ª×—×ª×•×Ÿ."}
    if is_duplicate_model_name(name):
        return {"success": False, "error": f"×”×©× '{name}' ×›×‘×¨ ×‘×©×™××•×©. ×™×© ×œ×‘×—×•×¨ ×©× ××—×¨."}
    return {"success": True}

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def revert_temp_metadata(current_slug: str, original_slug: str):
    from state_manager import revert_metadata
    ok = revert_metadata(current_slug, original_slug)
    return {"success": ok}

<<<<<<< HEAD

@eel.expose
def save_model_metadata(model_name, user, description):
    return save_fn(model_name, user, description)

@eel.expose
def get_original_count(slug: str) -> int:
    metadata_path = os.path.join("models", slug, "metadata.json")
    if not os.path.exists(metadata_path):
        return 0
    try:
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        return metadata.get("original_count", 0)
    except Exception as e:
        print(f"×©×’×™××” ×‘×§×¨×™××ª original_count: {e}")
        return 0

=======
@eel.expose
def save_model_metadata(name):
    return save_fn(name)
>>>>>>> origin/main

@eel.expose
def update_generation_choice(slug, wants_generation, generated_requested):
    return update_generation_choice_fn(slug, wants_generation, generated_requested)

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def load_model_metadata(slug):
    return load_model_metadata_fn(slug)

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def finalize_model_generation(slug):
    return finalize_generation(slug)

@eel.expose
def generate_sets(slug):
    return asyncio.run(generate_sets_async(slug))

@eel.expose
def done_generating():
    """×¤×•× ×§×¦×™×” ×©×§×•×¨××ª ×œ-JavaScript ×›×“×™ ×œ×¡××Ÿ ×©×”×’'× ×¨×¦×™×” ×”×¡×ª×™×™××”"""
    pass  # ××™×Ÿ ×¦×•×¨×š ×‘×œ×•×’×™×§×” × ×•×¡×¤×ª ×›××Ÿ, ×–×” ×¨×§ ×œ×—×©×™×¤×”

<<<<<<< HEAD

=======
>>>>>>> origin/main
def update_total_count(slug: str, new_count: int):
    meta_path = Path(f"models/{slug}/metadata.json")
    if not meta_path.exists():
        print(f"×œ× × ××¦× ××˜××“××˜×” ×œ×¢×“×›×•×Ÿ: {meta_path}")
        return
    try:
        with open(meta_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        metadata["total_final_count"] = new_count
        metadata["last_updated"] = datetime.now().isoformat()
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"×¢×•×“×›×Ÿ ××˜××“××˜×”: total_final_count = {new_count}")
    except Exception as e:
        print(f"×©×’×™××” ×‘×¢×“×›×•×Ÿ ×”××˜××“××˜×”: {e}")

<<<<<<< HEAD

@eel.expose
def append_to_generated_raw(slug, example):
=======
@eel.expose
def append_to_generated_raw(slug, example):
    print("ğŸ“¥ append_to_generated_raw ×”×•×¤×¢×œ×”")
>>>>>>> origin/main
    try:
        path = Path(f"models/{slug}/generated_raw.json")
        if not path.exists():
            data = []
        else:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)

        data.append({
            "question": example.get("question", "").strip(),
            "answer": example.get("answer", "").strip()
        })

        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        update_total_count(slug, len(data))
        return {"success": True}
    except Exception as e:
        print(f"×©×’×™××” ×‘×©××™×¨×ª ×©××œ×” ×—×“×©×”: {e}")
        return {"success": False, "error": str(e)}
<<<<<<< HEAD


=======
    
>>>>>>> origin/main
@eel.expose
def delete_from_generated_raw(slug, index):
    try:
        path = Path(f"models/{slug}/generated_raw.json")
        if not path.exists():
            return {"success": False, "error": "×œ× × ××¦× ×§×•×‘×¥ generated_raw."}

        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        if 0 <= index < len(data):
            del data[index]
        else:
            return {"success": False, "error": "××™× ×“×§×¡ ×œ× ×—×•×§×™."}

        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        update_total_count(slug, len(data))
        return {"success": True}
    except Exception as e:
        print(f"×©×’×™××” ×‘××—×™×§×ª ×©××œ×”: {e}")
        return {"success": False, "error": str(e)}

<<<<<<< HEAD

=======
>>>>>>> origin/main
async def generate_sets_async(slug):
    try:
        excel_path = os.path.join("models", slug, "original.xlsx")
        if not os.path.exists(excel_path):
            print(f"×©×’×™××”: ×œ× × ××¦× ×§×•×‘×¥ Excel ×‘×ª×™×§×™×™×” models/{slug}")
            return {"success": False}

        print(f"×§×•×‘×¥ ×”××§×¡×œ ×©× ×‘×—×¨: {excel_path}")
        df = pd.read_excel(excel_path)
        print("×¢××•×“×•×ª ×©× ××¦××• ×‘×§×•×‘×¥:", df.columns.tolist())

        question_col, answer_col, topic_col = None, None, None

        for col in df.columns:
            if col.lower() in ["question", "×©××œ×”"]:
                question_col = col
            if col.lower() in ["answer", "×ª×©×•×‘×”"]:
                answer_col = col
            if col.lower() in ["topic", "× ×•×©×"]:
                topic_col = col

        if not question_col or not answer_col:
            print("×œ× × ××¦××• ×¢××•×“×•×ª ×©××œ×” ×•×ª×©×•×‘×” ×ª×§×™× ×•×ª.")
            return {"success": False}

        original_data = []
        for _, row in df.iterrows():
            question = str(row.get(question_col, "")).strip()
            answer = str(row.get(answer_col, "")).strip()
            topic = str(row.get(topic_col, "×›×œ×œ×™")).strip()

            if question and answer:
                original_data.append({
                    "question": question,
                    "answer": answer,
                    "topic": topic if topic else "×›×œ×œ×™"
                })

        if not original_data:
            print("×œ× × ××¦××• ×©××œ×•×ª ×ª×§×™× ×•×ª ×‘×§×•×‘×¥.")
            return {"success": False}

        metadata = load_model_metadata(slug)
<<<<<<< HEAD
        model_name = metadata.get("model_name", slug)
=======
        model_name = metadata.get("model_name", slug)  # × ×©×ª××© ×‘×©× ×”××§×•×¨×™ ×¨×§ ×œ×¦×•×¨×›×™ ×ª×™×¢×•×“
>>>>>>> origin/main
        selected_sets = metadata.get("generated_requested", 0)

        if selected_sets <= 0:
            print(f"×©×’×™××”: ×œ× ×”×•×’×“×¨ ××¡×¤×¨ ×¡×˜×™× ×œ×’'× ×¨×¦×™×” ×‘××˜××“××˜×” ×œ××•×“×œ '{slug}'.")
            return {"success": False}

        await generate_by_topics(original_data, selected_sets, slug)

        return {"success": True}

    except Exception as e:
        print(f"×©×’×™××” ×‘×’'× ×¨×¦×™×”: {e}")
        return {"success": False}
<<<<<<< HEAD


=======
    
>>>>>>> origin/main
@eel.expose
def load_generated_data(slug):
    filepath = f"models/{slug}/generated_raw.json"
    if not os.path.exists(filepath):
        return []

    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
        return data

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def export_model_to_excel(model_name):
    try:
        print(f"××ª×—×™×œ ×™×™×¦×•× ×œ××•×“×œ: {model_name}")
<<<<<<< HEAD

        # ×§×•×‘×¥ ×”××§×•×¨
        data_path = os.path.join("models", model_name, "generated_raw.json")
        print(f"××—×¤×© ××ª ×”×§×•×‘×¥: {data_path}")

=======
        
        # ×‘×“×™×§×ª ×”× ×ª×™×‘ ×”×—×“×©
        data_path = f"models/{model_name}/generated_raw.json"
        print(f"××—×¤×© ××ª ×”×§×•×‘×¥: {data_path}")
        
>>>>>>> origin/main
        if not os.path.exists(data_path):
            print(f"×§×•×‘×¥ {data_path} ×œ× ×§×™×™×!")
            return None

<<<<<<< HEAD
        # ×§×¨×™××ª ×”× ×ª×•× ×™×
        with open(data_path, "r", encoding="utf-8") as file:
            dataset = json.load(file)

        if not dataset:
            print(" ×”×§×•×‘×¥ ×¨×™×§.")
            return None

        # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×™×¢×“ ×‘×ª×•×š web
        export_dir = os.path.join("web", "exports")
        os.makedirs(export_dir, exist_ok=True)

        file_name = f"{model_name}_dataset.xlsx"
        output_path = os.path.join(export_dir, file_name)

        # ×™×¦×™×¨×ª ×”×§×•×‘×¥
=======
        print(f"×§×•×‘×¥ × ××¦×: {data_path}")

        output_dir = "exports"
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"{model_name}_dataset.xlsx")

        # ×§×¨×™××ª ×”× ×ª×•× ×™×
        try:
            with open(data_path, "r", encoding="utf-8") as file:
                dataset = json.load(file)
                print(f"âœ… × ×ª×•× ×™× × ×§×¨××• ×‘×”×¦×œ×—×”. ××¡×¤×¨ ×¨×©×•××•×ª: {len(dataset)}")
        except json.JSONDecodeError as e:
            print(f"×©×’×™××” ×‘×§×¨×™××ª JSON: {e}")
            return None

        # ×× ×”× ×ª×•× ×™× ×¨×™×§×™×
        if not dataset:
            print("×”× ×ª×•× ×™× ×¨×™×§×™× â€“ ×œ× × ×•×¦×¨ ×§×•×‘×¥.")
            return None

        # ×™×¦×™×¨×ª ×§×•×‘×¥ ××§×¡×œ
>>>>>>> origin/main
        workbook = openpyxl.Workbook()
        sheet = workbook.active
        sheet.title = "×©××œ×•×ª ×•×ª×©×•×‘×•×ª"
        sheet.append(["×©××œ×”", "×ª×©×•×‘×”"])

<<<<<<< HEAD
        for index, item in enumerate(dataset):
            question = item.get("question", "")
            answer = item.get("answer", "")
            sheet.append([question, answer])

        workbook.save(output_path)
        print(f" × ×©××¨ ×‘Ö¾: {output_path}")

        return f"exports/{file_name}"  # ×™×—×¡×™ ××ª×•×š ×ª×™×§×™×™×ª web
=======
        # ×”×•×¡×¤×ª ×”× ×ª×•× ×™×
        for index, item in enumerate(dataset):
            try:
                question = item.get("question", "")
                answer = item.get("answer", "")
                print(f"×©×•×¨×” {index + 1}: ×©××œ×” = {question}, ×ª×©×•×‘×” = {answer}")
                sheet.append([question, answer])
            except Exception as e:
                print(f"×©×’×™××” ×‘×”×•×¡×¤×ª ×©×•×¨×” {index + 1}: {e}")
                continue

        # ×©××™×¨×ª ×”×§×•×‘×¥
        workbook.save(output_path)
        print(f"×§×•×‘×¥ ××§×¡×œ × ×©××¨ ×‘× ×ª×™×‘: {output_path}")

        return output_path
>>>>>>> origin/main

    except Exception as e:
        print(f"×©×’×™××” ×‘×™×¦×•× ×”× ×ª×•× ×™× ×œ××§×¡×œ: {e}")
        return None

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def cleanup_upload():
    cleanup_all()
    return {"success": True}

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def get_temp_model_name():
    meta = load_temp_metadata()
    return meta.get("model_name", "")

<<<<<<< HEAD

=======
>>>>>>> origin/main
@eel.expose
def get_temp_metadata():
    return load_temp_metadata()

<<<<<<< HEAD

@eel.expose
def load_params():
    base_path = Path(getattr(sys, '_MEIPASS', Path.cwd()))
    path = base_path / 'params.json'

    if not path.exists():
        print(f"[load_params] ×œ× × ××¦×: {path}")
        return []

    return json.loads(path.read_text(encoding='utf-8'))

=======
@eel.expose
def load_params():
    """
    ×§×•×¨× ××ª params.json ×•××—×–×™×¨ ××•×ª×• ×›××•×‘×™×™×§×˜ ×©×™×©××© ×‘Ö¾JS
    """
    p = Path(__file__).parent / 'params.json'
    return json.loads(p.read_text(encoding='utf-8'))
>>>>>>> origin/main

@eel.expose
def prepare_final_dataset(slug):
    # ×©×œ×™×¤×ª ×”××˜××“××˜×”
    metadata_path = os.path.join('models', slug, 'metadata.json')
    if not os.path.exists(metadata_path):
        raise FileNotFoundError(f"Metadata file not found for slug: {slug}")

    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    model_dir = os.path.join('models', slug)
    os.makedirs(model_dir, exist_ok=True)
    final_path = os.path.join(model_dir, "final_dataset.json")

    if metadata.get('user_generated'):
        # ×”××©×ª××© ×‘×—×¨ ×‘×’'× ×¨×¦×™×”
        generated_data_path = os.path.join('models', slug, 'generated_raw.json')
        if not os.path.exists(generated_data_path):
            raise FileNotFoundError("Generated raw data not found.")
        shutil.copy(generated_data_path, final_path)
        print(f"Copied generated data to {final_path}")
    else:
<<<<<<< HEAD
        excel_path = os.path.join('models', slug, 'original.xlsx')
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"No uploaded Excel file found at: {excel_path}")

        df = pd.read_excel(excel_path)

        column_mapping = {
            "×©××œ×”": "question",
            "×ª×©×•×‘×”": "answer",
            "× ×•×©×": "topic"
        }
        df.rename(columns=column_mapping, inplace=True)

        df.to_json(final_path, orient='records', force_ascii=False, indent=4)
        print(f"Converted Excel to JSON at {final_path}")

    if metadata.get('user_generated') is False:
        generated_data_path = os.path.join('models', slug, 'generated_raw.json')
        if os.path.exists(generated_data_path):
            os.remove(generated_data_path)
            print(f"âœ”ï¸ × ××—×§ generated_raw.json ×¢×‘×•×¨ ××•×“×œ {slug} ×›×™ user_generated = False")

    return final_path

@eel.expose
def ensure_generated_from_original(slug):
    generated_path = os.path.join("models", slug, "generated_raw.json")
    if os.path.exists(generated_path):
        return {"created": False}

    # ×™×•×¦×¨×™× ××•×ª×• ××ª×•×š original.xlsx
    excel_path = os.path.join("models", slug, "original.xlsx")
    if not os.path.exists(excel_path):
        return {"success": False, "error": "×œ× × ××¦× ×§×•×‘×¥ original.xlsx"}

    df = pd.read_excel(excel_path)
    data = []
    for _, row in df.iterrows():
        question = str(row.get("×©××œ×”", "")).strip()
        answer = str(row.get("×ª×©×•×‘×”", "")).strip()
        if question and answer:
            data.append({"question": question, "answer": answer})

    with open(generated_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return {"created": True}



@eel.expose
def save_training_config(config):
    slug = config.get('slug')
    if not slug:
        return {"success": False, "error": "Training config must include a 'slug' key."}
=======
        # ×”××©×ª××© ×”×¢×œ×” ×§×•×‘×¥
        excel_files = glob.glob("uploads/*.xlsx")
        if not excel_files:
            raise FileNotFoundError("No Excel files found in uploads.")

        latest_excel = max(excel_files, key=os.path.getmtime)
        df = pd.read_excel(latest_excel)
        df.to_json(final_path, orient='records', force_ascii=False, indent=4)
        print(f"Converted Excel '{latest_excel}' to JSON at {final_path}")
        
    return final_path

@eel.expose
def save_training_config(config):
    import datetime

    slug = config.get('slug')
    if not slug:
        raise ValueError("Training config must include a 'slug' key.")
>>>>>>> origin/main

    model_dir = os.path.join("models", slug)
    os.makedirs(model_dir, exist_ok=True)

<<<<<<< HEAD
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
=======
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
>>>>>>> origin/main
    filename = f"training_config_{timestamp}.json"
    config_path = os.path.join(model_dir, filename)

    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=4)

    print(f"Training config saved at {config_path}")
<<<<<<< HEAD
    return {"success": True, "path": config_path}

@eel.expose
def start_training_from_path(config_path):
    def run_training():
        slug = startTrain(config_path)
        notify_all(slug)

    thread = threading.Thread(target=run_training)
    thread.start()
    return {"success": True}

@eel.expose
def register_email_for_notification(email):
    register_email(email)


@eel.expose
def prepare_model_for_testing(slug, temperature, max_tokens):
    import os
    import glob
    from trainingConfig import TrainingConfig
    import Train
    from Train import findLastAdapter, setTestModel

    # ×˜×•×¢× ×™× ××ª ×§×•×‘×¥ ×”×§×•× ×¤×™×’ ×”×›×™ ×¢×“×›× ×™
    configs = sorted(
        glob.glob(os.path.join("models", slug, "training_config_*.json")),
        reverse=True
    )
    if not configs:
        raise FileNotFoundError(f"âš  ×œ× × ××¦× ×§×•×‘×¥ ×§×•× ×¤×™×’ ×œ××•×“×œ '{slug}'")
    config_path = configs[0]
    config = TrainingConfig.from_directory(config_path)

    # ×©××™×¨×ª ×”××•×“×œ ×•×”×ª×‘× ×™×ª ×‘×ª×•×š ××©×ª× ×™× ×’×œ×•×‘×œ×™×™×
    Train.baseModel = Train.models[config.model_name]["source"]
    Train.template = Train.models[config.model_name]["template"]

    # ××•×¦××™× ××ª ×ª×™×§×™×™×ª ×”×¨×™×¦×” ×”××—×¨×•× ×”
    runs = sorted([
        d for d in os.listdir(f"models/{slug}/trained")
        if os.path.isdir(os.path.join("models", slug, "trained", d)) and d.startswith("run_")
    ])
    if not runs:
        raise FileNotFoundError(f"âš  ×œ× × ××¦××• ×ª×™×§×™×•×ª run_ ×¢×‘×•×¨ ×”××•×“×œ '{slug}'")
    run_id = runs[-1]
    run_path = os.path.join("models", slug, "trained", run_id)

    Train.outputDir = run_path

    # ××•×¦××™× ××ª ×”××“×¤×˜×¨ ×”××—×¨×•×Ÿ
    adapter_path = findLastAdapter(run_path)

    # ×˜×•×¢× ×™× ××ª ×”××•×“×œ ×¢× ×”××“×¤×˜×¨
    setTestModel(temperature, adapter_path, max_tokens)



@eel.expose
def ask_model_js(question_text, temperature, max_tokens=512):
    response = question(question_text, temperature, max_tokens)
    if isinstance(response, list):
        for msg in reversed(response):
            if msg.get("role") == "assistant":
                return msg.get("content", "[×©×’×™××”: ××™×Ÿ ×ª×•×›×Ÿ]")
        return "[×©×’×™××”: ×œ× × ××¦××” ×ª×©×•×‘×” ××”××•×“×œ]"
    return str(response)


@eel.expose
def export_zip_package(slug):
    import zipfile

    try:
        model_dir = os.path.join("models", slug)
        export_dir = os.path.join("web", "exports")
        os.makedirs(export_dir, exist_ok=True)

        zip_filename = f"{slug}_export_package.zip"
        zip_path = os.path.join(export_dir, zip_filename)

        with zipfile.ZipFile(zip_path, 'w') as zipf:
            # ×§×•×‘×¥ ×§×•× ×¤×™×’ ×”×›×™ ×¢×“×›× ×™
            configs = sorted(
                glob.glob(os.path.join(model_dir, "training_config_*.json")),
                reverse=True
            )
            if not configs:
                return {"success": False, "error": "×œ× × ××¦× ×§×•×‘×¥ ×”×’×“×¨×•×ª"}
            zipf.write(configs[0], arcname=os.path.basename(configs[0]))

            # ×¨×§ ×§×•×‘×¥ original.xlsx
            excel_path = os.path.join(model_dir, "original.xlsx")
            if not os.path.exists(excel_path):
                return {"success": False, "error": "×œ× × ××¦× ×§×•×‘×¥ original.xlsx"}
            zipf.write(excel_path, arcname="original.xlsx")

        print(f" ZIP ××•×›×Ÿ: {zip_path}")
        return {"success": True, "zip_path": f"exports/{zip_filename}"}

    except Exception as e:
        print(f"×©×’×™××” ×‘×™×¦×™×¨×ª ZIP: {e}")
        return {"success": False, "error": str(e)}

@eel.expose
def export_model_js(slug, q_type="f16"):
    zip_path = exportModel(slug, q_type)

    if zip_path:
        return {"success": True, "zip_path": zip_path}
    else:
        return {"success": False, "error": "×œ× × ×•×¦×¨ ×§×•×‘×¥ ZIP"}


MODELS_DIR: str = "models"

@eel.expose
def get_all_models_metadata():
    models = []
    for subdir in os.listdir(MODELS_DIR):
        model_path = os.path.join(MODELS_DIR, subdir)
        if os.path.isdir(model_path):
            metadata_path = os.path.join(model_path, "metadata.json")
            if os.path.exists(metadata_path):
                try:
                    with open(metadata_path, "r", encoding="utf-8") as f:
                        metadata = json.load(f)

                    # ×—×™×¤×•×© ×§×‘×¦×™ training_config
                    # training_configs = glob.glob(os.path.join(model_path, "training_config_*.json"))
                    valid_runs = check_valid_runs(subdir)
                    tweaks_count = len(valid_runs)

                    # ×ª××¨×™×š
                    raw_date = metadata.get("last_updated", "")
                    if raw_date:
                        dt = datetime.fromisoformat(raw_date)
                        formatted_date = f"{dt.day}/{dt.month}/{dt.year}"
                    else:
                        formatted_date = "â€”"

                    models.append({
                        "slug": metadata.get("slug", subdir),
                        "name": metadata.get("model_name", "×œ×œ× ×©×"),
                        "user": metadata.get("user", "â€”"),
                        "description": metadata.get("description", "â€”"),
                        "tweaks": tweaks_count,
                        "updated_at": formatted_date,
                        "last_updated_raw": raw_date
                    })
                except Exception as e:
                    print(f"×©×’×™××” ×‘×§×¨×™××ª ××˜××“××˜×” ××ª×•×š {metadata_path}: {e}")
    return models

def check_valid_runs(slug):
    run_dir = os.path.join("models", slug, "trained")
    if not os.path.exists(run_dir):
        return []

    valid_runs = []
    for run in os.listdir(run_dir):
        run_path = os.path.join(run_dir, run)
        if os.path.isdir(run_path) and run.startswith("run_"):
            adapter_path = os.path.join(run_path, "adapter_config.json")
            if os.path.exists(adapter_path):
                valid_runs.append(run)
            else:
                shutil.rmtree(run_path)  # ×× ×§×™× ××ª ×”×¨×™×¦×” ×”×œ× ×ª×§×™× ×”
                print(f"× ××—×§×” ×¨×™×¦×” ×œ× ×ª×§×™× ×”: {run_path}")

    return valid_runs

@eel.expose
def open_or_export_model(slug, q_type="f16"):
    from Train import exportModel, findLastAdapter
    import glob

    model_dir = os.path.join("models", slug)

    # ××•×¦××™× ××ª ×”×¨×™×¦×” ×”××—×¨×•× ×”
    runs = sorted(
        [d for d in os.listdir(os.path.join(model_dir, "trained")) if d.startswith("run_")],
        reverse=True
    )

    if not runs:
        return {"success": False, "error": "×œ× × ××¦××” ××£ ×”×¨×¦×ª ××™××•×Ÿ."}

    last_run = runs[0]
    last_run_path = os.path.join(model_dir, "trained", last_run)

    # ×‘×“×™×§×” ×× ×§×™×™××ª ×ª×™×§×™×™×ª exported
    exported_path = os.path.join(last_run_path, "exported")
    if os.path.exists(exported_path):
        print(f" ××•×“×œ ×›×‘×¨ ×™×•×¦×: {exported_path}")
        open_model_folder(os.path.join(slug, "trained", last_run, "exported"))
        return {"success": True, "already_exported": True}

    # ×× ×œ× ×§×™×™× â€“ ××™×™×¦××™×
    zip_path = exportModel(slug, q_type)
    if zip_path:
        print(f" ××•×“×œ ×™×•×¦× ×¢×›×©×™×•: {zip_path}")
        folder_to_open = os.path.dirname(zip_path)
        open_model_folder(os.path.relpath(folder_to_open, "models"))
        return {"success": True, "already_exported": False}

    return {"success": False, "error": "×œ× × ×•×¦×¨ ×§×•×‘×¥ ZIP"}


@eel.expose
def open_model_folder(name):
    import subprocess
    import platform

    folder_path = os.path.abspath(os.path.join("models", name))

    if not os.path.exists(folder_path):
        return {"success": False, "error": "×”×ª×™×§×™×™×” ×œ× ×§×™×™××ª"}

    try:
        if platform.system() == "Windows":
            os.startfile(folder_path)
        elif platform.system() == "Darwin":
            subprocess.Popen(["open", folder_path])
        else:
            subprocess.Popen(["xdg-open", folder_path])
        return {"success": True}
    except Exception as e:
        return {"success": False, "error": str(e)}


@eel.expose
def cleanup_on_close():
    temp_meta = load_temp_metadata()
    slug = temp_meta.get("slug")
    model_name = temp_meta.get("model_name")

    if slug and model_name is None:
        model_path = os.path.join("models", slug)
        if os.path.exists(model_path):
            shutil.rmtree(model_path)
            print(f"× ××—×§×” ×ª×™×§×™×™×ª ×”××•×“×œ: {slug}")
        cleanup_all()
    else:
        print("××™×Ÿ ××•×“×œ ×–×× ×™ ×¤×¢×™×œ. ")
=======
    return config_path
>>>>>>> origin/main


webbrowser.open_new("http://localhost:8001/home.html")
eel.start("home.html", mode=None, host="localhost", port=8001)
<<<<<<< HEAD




=======
>>>>>>> origin/main
