[
  {
    "key": "learning_rate",
    "type": "range",
    "label": "באיזו מהירות המודל יסתגל למידע חדש?",
    "tooltip": "Learning rate\n\nשולט על כמה מהר המודל מתאים את עצמו לדוגמאות החדשות.\nערך גבוה אומר שהמודל לומד מהר אבל יכול לפספס,\nוערך נמוך אומר שהמודל לומד בצורה איטית אבל בזהירות ובהדרגה.\nאז מה מתאים?\nערך נמוך מתאים למידע מורכב או רגיש.\nערך גבוה מתאים כשיש מעט זמן או כשהמידע מאוד אחיד וברור.",
    "realRange": { "min": 1e-5, "max": 2e-4, "default": 5e-5 },
    "endpoints": [
      "לאט אך זהיר ומדויק",
      "מהיר אך עלול לטעות"
    ]
  },
  {
    "key": "model_name",
    "type": "select",
    "label": "באיזה מודל בסיס תרצו להשתמש?",
    "tooltip": "Model name\n\nהמודל שעליו יתבצע האימון.\nכל מודל מגיע עם יכולות בסיס שונות שמתאימות למשימות אחרות.\nאז מה מתאים?\nבחרו מודל שמתאים לגודל המידע ולמטרה שלכם.\nלמשל: LLaMA 3 מתאים למשימות כלליות ומורכבות.",
    "options": [
      { "value": "llama-3-8b-instruct", "label": "Llama 3 8B Instruct" },
      { "value": "DeepSeek-R1-Distill-Llama-8B", "label": "DeepSeek R1 Distill Llama 8B" },
      { "value": "Mistral-7B-Instruct-v0.3", "label": "Mistral 7B Instruct v0.3" },
      { "value": "Aya-23-8B-Chat", "label": "Aya 23 8B Chat" },
      { "value": "Yi-6B-Chat", "label": "Yi 6B Chat" },
      { "value": "Qwen-7B", "label": "Qwen 7B" }
    ],
    "default": "Aya-23-8B-Chat"
  },
  {
    "key": "num_epochs",
    "type": "range",
    "label": "כמה פעמים המודל יחזור על החומר?",
    "tooltip": "Num epochs\n\nכמה פעמים המודל עובר על המידע כולו.\nכל מעבר עוזר לו לדייק יותר,\nאבל יותר מדי פעמים עלול לגרום לו 'לזכור בעל פה' במקום להבין את המשמעות.\nאז מה מתאים?\nמספר נמוך מתאים כשיש הרבה מידע או כשצריך תוצאה מהירה.\nמספר גבוה מתאים כשיש מעט מידע ורוצים שהמודל יפנים טוב יותר.",
    "realRange": { "min": 1, "max": 10, "default": 4 },
    "endpoints": [
      "קצת כדי ללמוד מהר יותר",
      "הרבה כדי להבין לעומק"
    ]
  },
  {
    "key": "gradient_accumulation_steps",
    "type": "range",
    "label": "על מה עדיף שהמודל יתעכב?",
    "tooltip": "Gradient accumulation steps\n\nכמה פעמים המודל ילמד לפני שהוא יעדכן את עצמו.\nהמודל לומד ״שורה מהמחברת״ כל פעם,\nורק אחרי כמה שורות הוא עוצר כדי לעדכן את מה שהבין.\nהדבר מאפשר לו ללמוד בצורה יציבה יותר כשהמחשב לא חזק במיוחד.\nאז מה מתאים?\nערך גבוה מתאים כשיש מגבלת זיכרון ורוצים לדמות batch גדול.\nערך נמוך מתאים כשיש מספיק זיכרון ורוצים עדכונים תכופים ומהירים.",
    "realRange": { "min": 1, "max": 8, "default": 8 },
    "endpoints": [
      "בדיקה של חומר שלמד",
      "למידה של חומר חדש"
    ]
  },
  {
    "key": "warmup_ratio",
    "type": "range",
    "label": "כמה זמן ייקח למודל להתחיל ללמוד בקצב מלא?",
    "tooltip": "Warmup ratio\n\nכמה קצב הלמידה יעלה בהדרגה.\nעל מנת למנוע שינויים חדים ובשביל לפתח כיווני למידה טובים,\nהמודל לומד בקצב הדרגתי לפני שהוא מתחיל ללמוד בקצב מלא.\nאז מה מתאים?\nערך גבוה מתאים למידע רועש או מודלים רגישים.\nערך נמוך מתאים למידע פשוט ורצון לאימון מהיר.",
    "realRange": { "min": 0.0, "max": 0.5, "default": 0.2 },
    "endpoints": [
      "התחלה מהירה ולמידה מיידית",
      "התחלה איטית ועלייה הדרגתית"
    ]
  },
    {
    "key": "batch_size",
    "type": "select",
    "label": "כמה דוגמאות המודל יעבד בכל פעם?",
    "tooltip": "Batch size\n\nכמה דוגמאות המודל 'רואה' בכל שלב של הלמידה.\nקבוצות קטנות חוסכות בזיכרון,\nוקבוצות גדולות משפרות יעילות (במידה ולמחשב יש מספיק זיכרון גרפי כדי לעמוד בזה).\nאז מה מתאים?\nערך נמוך מתאים למחשבים עם GPU חלש או כשרוצים יציבות בלמידה.\nערך גבוה מתאים למחשבים חזקים ולמקרים בהם חשוב לאמן מהר.",
    "realRange": { "min": 2, "max": 4, "default": 2 },
    "options": [
      { "value": 2, "label": "קצת כדי לחסוך בזיכרון המחשב" },
      { "value": 4, "label": "הרבה כדי ללמוד בצורה יעילה" }
    ],
      "default": 2
  },
  {
    "key": "max_seq_length",
    "type": "select",
    "label": "כמה מידע המודל יכול לעבוד בו זמנית?",
    "tooltip": "Max sequence length\n\nכמה טקסט המודל מסוגל לעבד במקביל.\nככל שהמספר גבוה יותר, המודל מבין הקשר רחב יותר אך דורש זיכרון גרפי רב יותר.\nאז מה מתאים?\nערך גבוה מתאים לטקסטים ארוכים או שיחות.\nערך נמוך מתאים למידע קצר, כמו שאלות ותשובות בסיסיות.",
    "options": [
      { "value": 2048, "label": "טקסטים ארוכים" },
      { "value": 1024, "label": "מאוזן" },
      { "value": 512, "label": "טקסטים קצרים" }
    ],
    "default": 1024
  },
  {
    "key": "fp16",
    "type": "select",
    "label": "באיזה מצב דיוק המודל ישתמש?",
    "tooltip": "FP16\n\nרמת הדיוק של החישובים.\nמצב FP16 מהיר יותר אבל פחות מדויק (מתאים למחשבים חלשים ומודלים גדולים).\nמצב FP32 מדויק יותר, אבל כבד יותר למחשב ודורש יותר זיכרון גרפי.\nאז מה מתאים?\nFP16 מתאים כשעובדים עם GPU בינוני ורוצים לחסוך זמן/זיכרון.\nFP32 מתאים כשיש צורך בדיוק מרבי או שיש מספיק משאבים.",
    "options": [
      { "value": false, "label": "דיוק מלא" },
      { "value": true,  "label": "מהיר ופחות מדויק" }
    ],
    "default": true
  }
]
