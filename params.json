[
  {
    "key": "learning_rate",
    "type": "range",
    "label": "באיזו מהירות המודל יסתגל למידע חדש?",
<<<<<<< HEAD
"tooltip": "Learning rate\n\nשולט על כמה מהר המודל מתאים את עצמו לדוגמאות החדשות.\nערך גבוה אומר שהמודל לומד מהר אבל יכול לפספס,\nוערך נמוך אומר שהמודל לומד בצורה איטית אבל בזהירות ובהדרגה.\nאז מה מתאים?\nערך נמוך מתאים למידע מורכב או רגיש.\nערך גבוה מתאים כשיש מעט זמן או כשהמידע מאוד אחיד וברור.\n\nשימו לב: ערך נמוך יאריך משמעותית את זמן האימון, אך הוא בחירה טובה כשנדרשת זהירות בלמידה.\n",
    "realRange": { "min": 1e-5, "max": 2e-4, "default": 5e-5 },
=======
    "tooltip": "ערך לוגריתמי בין 1e-5 (איטי וזהיר) ל-1e-3 (מהיר אך פחות מדויק)",
    "realRange": { "min": 1e-5, "max": 1e-3, "default": 3e-4 },
>>>>>>> origin/main
    "endpoints": [
      "לאט אך זהיר ומדויק",
      "מהיר אך עלול לטעות"
    ]
  },
  {
<<<<<<< HEAD
    "key": "model_name",
    "type": "select",
    "label": "באיזה מודל בסיס תרצו להשתמש?",
    "tooltip": "Model name\n\nהמודל שעליו יתבצע האימון.\nכל מודל מגיע עם יכולות בסיס שונות שמתאימות למשימות אחרות.\nאז מה מתאים?\nבחרו מודל לפי גודל המידע והמטרה שלו.\nלמשל: LLaMA 3 מתאים למשימות כלליות ומורכבות.",
    "options": [
      { "value": "llama-3-8b-instruct", "label": "Llama 3 8B Instruct" },
      { "value": "DeepSeek-R1-Distill-Llama-8B", "label": "DeepSeek R1 Distill Llama 8B" },
      { "value": "Mistral-7B-Instruct-v0.3", "label": "Mistral 7B Instruct v0.3" },
      { "value": "Aya-23-8B-Chat", "label": "Aya 23 8B Chat" },
      { "value": "Yi-6B-Chat", "label": "Yi 6B Chat" },
      { "value": "Qwen-7B", "label": "Qwen 7B" }
    ],
    "default": "Aya-23-8B-Chat"
=======
    "key": "batch_size",
    "type": "range",
    "label": "כמה דוגמאות המודל יעבד בכל פעם?",
    "tooltip": "מיפוי ליניארי מ-4 (קצת) עד 64 (הרבה)",
    "realRange": { "min": 4, "max": 64, "default": 32 },
    "endpoints": [
      "קצת כדי לחסוך בזיכרון המחשב",
      "הרבה כדי ללמוד בצורה יעילה"
    ]
>>>>>>> origin/main
  },
  {
    "key": "num_epochs",
    "type": "range",
    "label": "כמה פעמים המודל יחזור על החומר?",
<<<<<<< HEAD
"tooltip": "Num epochs\n\nכמה פעמים המודל עובר על המידע כולו.\nכל מעבר עוזר לו לדייק יותר, אבל יותר מדי פעמים עלול לגרום לו 'לזכור בעל פה' במקום להבין את המשמעות.\nאז מה מתאים?\nמספר נמוך מתאים כשיש הרבה מידע או כשצריך תוצאה מהירה.\nמספר גבוה מתאים כשיש מעט מידע ורוצים שהמודל יפנים טוב יותר.\n\nשימו לב: מספר גבוה עלול להאריך משמעותית את זמן האימון, אך הוא בחירה טובה כשחשוב שהמודל ילמד לעומק.",
=======
    "tooltip": "מיפוי ליניארי בין 1 (קצר) ל-10 (ארוך)",
>>>>>>> origin/main
    "realRange": { "min": 1, "max": 10, "default": 4 },
    "endpoints": [
      "קצת כדי ללמוד מהר יותר",
      "הרבה כדי להבין לעומק"
    ]
  },
  {
    "key": "gradient_accumulation_steps",
    "type": "range",
    "label": "על מה עדיף שהמודל יתעכב?",
<<<<<<< HEAD
    "tooltip": "Gradient accumulation steps\n\nכמה פעמים המודל ילמד לפני שהוא יעדכן את עצמו.\nהמודל לומד ״שורה מהמחברת״ כל פעם,\nורק אחרי כמה שורות הוא עוצר כדי לעדכן את מה שהבין.\nהדבר מאפשר לו ללמוד בצורה יציבה יותר כשהמחשב לא חזק במיוחד.\nאז מה מתאים?\nערך גבוה מתאים כשיש מגבלת זיכרון ורוצים לאפשר למודל לאסוף מידע מכמה דוגמאות לפני עדכון.\nערך נמוך מתאים כשיש מספיק זיכרון ורוצים עדכונים תכופים ומהירים.",
=======
    "tooltip": "מספר צעדים לאצירת גרדיאנטים לפני עדכון המשקלות",
>>>>>>> origin/main
    "realRange": { "min": 1, "max": 8, "default": 8 },
    "endpoints": [
      "בדיקה של חומר שלמד",
      "למידה של חומר חדש"
    ]
  },
  {
    "key": "warmup_ratio",
    "type": "range",
    "label": "כמה זמן ייקח למודל להתחיל ללמוד בקצב מלא?",
<<<<<<< HEAD
    "tooltip": "Warmup ratio\n\nכמה קצב הלמידה יעלה בהדרגה.\nעל מנת למנוע שינויים חדים ובשביל לפתח כיווני למידה טובים,\nהמודל לומד בקצב הדרגתי לפני שהוא מתחיל ללמוד בקצב מלא.\nאז מה מתאים?\nערך גבוה מתאים למידע לא אחיד או מודלים רגישים.\nערך נמוך מתאים למידע פשוט ורצון לאימון מהיר.",
    "realRange": { "min": 0.0, "max": 0.5, "default": 0.2 },
=======
    "tooltip": "ערך בין 0.0 (מיידי) ל-0.3 (עלייה הדרגתית)",
    "realRange": { "min": 0.0, "max": 0.3, "default": 0.2 },
>>>>>>> origin/main
    "endpoints": [
      "התחלה מהירה ולמידה מיידית",
      "התחלה איטית ועלייה הדרגתית"
    ]
  },
<<<<<<< HEAD
    {
    "key": "batch_size",
    "type": "select",
    "label": "כמה דוגמאות המודל יעבד בכל פעם?",
    "tooltip": "Batch size\n\nכמה דוגמאות המודל 'רואה' בכל שלב של הלמידה.\nקבוצות קטנות חוסכות בזיכרון,\nוקבוצות גדולות משפרות יעילות (במידה ולמחשב יש מספיק זיכרון גרפי כדי לעמוד בזה).\nאז מה מתאים?\nקצת דוגמאות מתאימות למחשבים עם GPU חלש או כשחשובה יציבות בלמידה.\nהרבה דוגמאות מתאימות למחשבים חזקים או כשמעוניינים באימון מהיר.\n\nשימו לב: בחירה בכמות קטנה של דוגמאות תאט את האימון, אך תאפשר עבודה גם על מחשבים עם יכולת גרפית מוגבלת.",
    "realRange": { "min": 2, "max": 4, "default": 2 },
    "options": [
      { "value": 2, "label": "קצת כדי לחסוך בזיכרון המחשב" },
      { "value": 4, "label": "הרבה כדי ללמוד בצורה יעילה" }
    ],
      "default": 2
  },

=======
  {
    "key": "model_name",
    "type": "select",
    "label": "באיזה מודל בסיס תרצו להשתמש?",
    "tooltip": "בחרו את המודל שעליו יתבצע ה-fine-tuning",
    "options": [
      { "value": "llama-3-8b-instruct", "label": "Llama 3 8B Instruct" }
    ],
    "default": "llama-3-8b-instruct"
  },
>>>>>>> origin/main
  {
    "key": "max_seq_length",
    "type": "select",
    "label": "כמה מידע המודל יכול לעבוד בו זמנית?",
<<<<<<< HEAD
    "tooltip": "Max sequence length\n\nכמה טקסט המודל מסוגל לעבד במקביל.\nככל שהמספר גבוה יותר, המודל מבין הקשר רחב יותר אך דורש זיכרון גרפי רב יותר.\n\nאז מה מתאים?\nטקסטים ארוכים מתאימים לשיחות ותשובות מפורטות.\nטקסטים קצרים מתאימים למידע מדויק ותשובות בסיסיות.\n\nשימו לב: שימוש בטקסטים ארוכים עשוי להאט את האימון עקב עומס חישובי, אך הוא חשוב כשיש צורך להבין הקשרים מורכבים או טקסטים מרובי שורות.",
    "options": [
      { "value": 2048, "label": "טקסטים ארוכים" },
      { "value": 1024, "label": "מאוזן" },
      { "value": 512, "label": "טקסטים קצרים" }
    ],
    "default": 1024
=======
    "tooltip": "קיבולת הקשר של המודל; גבוה = זיכרון גבוה",
    "options": [
      { "value": 4096, "label": "טקסטים ארוכים" },
      { "value": 2048, "label": "מאוזן" },
      { "value": 1024, "label": "טקסטים קצרים" }
    ],
    "default": 2048
>>>>>>> origin/main
  },
  {
    "key": "fp16",
    "type": "select",
    "label": "באיזה מצב דיוק המודל ישתמש?",
<<<<<<< HEAD
    "tooltip": "FP16\n\nרמת הדיוק של החישובים.\nמצב מהיר אך פחות מדויק עדיף במחשבים חלשים או כשמאמנים מודלים גדולים.\nמצב דיוק מלא כבד יותר ודורש יותר זיכרון גרפי.\n\nאז מה מתאים?\n\"מהיר אך פחות מדויק\" מתאים כשעובדים עם GPU בינוני ורוצים לחסוך זמן/זיכרון.\n\"דיוק מלא\" מתאים כשיש צורך בדיוק מרבי ושיש מספיק משאבים.\n\nשימו לב: השימוש ב\"דיוק מלא\" יאריך משמעותית את זמן כוונון המודל אך הוא חשוב במידה ותרצו מודל מדויק עד כמה שניתן.",
=======
    "tooltip": "FP16 = מהיר אך פחות מדויק; FP32 = דיוק מלא",
>>>>>>> origin/main
    "options": [
      { "value": false, "label": "דיוק מלא" },
      { "value": true,  "label": "מהיר ופחות מדויק" }
    ],
    "default": true
  }
<<<<<<< HEAD
]
=======
]
>>>>>>> origin/main
